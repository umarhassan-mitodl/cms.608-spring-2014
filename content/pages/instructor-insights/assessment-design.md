---
content_type: page
description: ''
layout: instructor_insights
learning_resource_types: []
ocw_type: CourseSection
parent_title: Instructor Insights
parent_type: ThisCourseAtMITSection
parent_uid: 58bbf1fb-ceed-0939-abc9-3070d8f6b884
title: Assessment Design
uid: 9554499d-9d09-ed9f-a9e9-8de3755f881f
---

_In this section, Philip Tan and Richard Eberhardt describe how they assessed student learning._

The class was organized around {{% resource_link 0c532bff-cfdf-6a8c-2a45-eb1d552c2516 "three team projects" %}}. Students worked on two short-term (3-week) projects and one long-term (6-week) project. During Spring 2014, instructors assessed three team-produced artifacts associated with each project: 1) the rules and materials needed to play the game; 2) a written changelog, resembling software release notes, that documented key changes made to the the design of the game after each design session; and 3) a five-minute oral presentation (with visuals), during which team members provided a postmortem analysis of their design process. Individually, students created a fourth artifact: one-page written reports detailing how they worked in their teams. Each team was also responsible for bringing in playable versions of their games on specific days set aside for in-class playtesting. We used these artifacts to assess how well the games played, how effectively teams used the iterative design process in creating their games, and how well teams and individuals reflected on their design processes. 

{{< quote "We emphasized that last-minute changes would not rescue their games if they were not continually iterating on their games throughout the development process." "—Philip Tan and Richard Eberhardt" >}}

We, along with {{% resource_link "b3c1adb4-1ccb-4a9d-9e72-307e175804c8" "MIT Game Lab" %}} staff, played the games based on the delivered rules and materials to determine how well the games played. We determined whether or not a third party could play the games without assistance from the designers. As such, rules and materials were graded for legibility.

Throughout the semester, we communicated that we wanted students to develop their games based on external player behavior and stressed that it would be an organic and long-term process. We emphasized that last-minute changes would not rescue their games if they were not continually iterating on their games throughout the development process. The changelogs helped us determine how well the teams incorporated feedback from playtesting sessions into their game designs. This information, in turn, helped us assess the degree to which students were iterating on their projects over time.

The oral presentations and the individually-written papers were used to assess how well the students reflected on their design processes: Did they describe what they learned and how they arrived at that learning? Did they understand the mistakes they might have made in the design process?